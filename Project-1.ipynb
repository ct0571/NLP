{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "36853a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['towards', 'a', 'framework', 'for', 'understanding', 'the', 'performance', 'of', 'blockchains', 'm', 'touloupou', 'k', 'christodoulou', 'a', 'inglezakis', 'e', 'iosif', 'and', 'm', 'themistocleous', 'towards', 'a', 'framework', 'for', 'understanding', 'the', 'performance', 'of', 'blockchains', 'conference', 'on', 'blockchain', 'research', 'applications', 'for', 'innovative', 'networks', 'and', 'services', 'brains', 'pp', 'doi', 'abstractñ', 'blockchain', 'and', 'distributed', 'ledger', 'technology', 'dlt', 'appears']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random as rand\n",
    "\n",
    "# Execute the below lines ones\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "num_of_sentences = 5\n",
    "num_of_words = 10\n",
    "\n",
    "# Read the file and preprocess the text\n",
    "filename = \"/Users/chathurya/Downloads/papers.txt\"\n",
    "\n",
    "with open(filename, 'r', encoding = \"ISO-8859-1\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "content = [line.strip() for line in content if line.strip() != '']\n",
    "tokens = [word.lower() for line in content for word in nltk.word_tokenize(line)]\n",
    "refined_tokens = remove_punctuation(tokens)\n",
    "words = [word for word in refined_tokens if word.isalpha()]\n",
    "print(words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0c4a1080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and for in of inseparable that in technology private review\n",
      "[('and',), ('for',), ('in',), ('of',), ('inseparable',), ('that',), ('in',), ('technology',), ('private',), ('review',)]\n",
      "was scientific attacks makes regulatory methods after of risks is\n",
      "[('was',), ('scientific',), ('attacks',), ('makes',), ('regulatory',), ('methods',), ('after',), ('of',), ('risks',), ('is',)]\n",
      "for ensuring to i access time information the smart types\n",
      "[('for',), ('ensuring',), ('to',), ('i',), ('access',), ('time',), ('information',), ('the',), ('smart',), ('types',)]\n",
      "s we uses nonfungibletokens design students an shown to exposures\n",
      "[('s',), ('we',), ('uses',), ('nonfungibletokens',), ('design',), ('students',), ('an',), ('shown',), ('to',), ('exposures',)]\n",
      "blocks quickly of within included such technologies requires researchers the\n",
      "[('blocks',), ('quickly',), ('of',), ('within',), ('included',), ('such',), ('technologies',), ('requires',), ('researchers',), ('the',)]\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 sentences with 10 words \n",
    "unigrams = []\n",
    "freq_unigrams = nltk.FreqDist(words)\n",
    "for token_ in freq_unigrams.keys():\n",
    "    unigrams.append(token_)\n",
    "length = len(words)\n",
    "for i in range(num_of_sentences):\n",
    "    sentence = []\n",
    "    tokens_sentence = []\n",
    "    \n",
    "    for j in range(num_of_words):\n",
    "        word_ = []\n",
    "        index = rand.randint(20, length) - 10\n",
    "        sentence.append(words[index+j])\n",
    "        word_.append(words[index+j])\n",
    "        tokens_sentence.append(tuple(word_))\n",
    "    print(\" \".join(sentence))\n",
    "    print(tokens_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c5f353bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM:\n",
      "\n",
      "the advantages of usersõ loss of special laws on into\n",
      "[('the', 'advantages'), ('advantages', 'of'), ('of', 'usersõ'), ('usersõ', 'loss'), ('loss', 'of'), ('of', 'special'), ('special', 'laws'), ('laws', 'on'), ('on', 'into')]\n",
      "\n",
      "is introduced as research institutions and adjustable solutions to deal\n",
      "[('is', 'introduced'), ('introduced', 'as'), ('as', 'research'), ('research', 'institutions'), ('institutions', 'and'), ('and', 'adjustable'), ('adjustable', 'solutions'), ('solutions', 'to'), ('to', 'deal')]\n",
      "\n",
      "gas costs of nonfungibletokens nft the centralized system based on\n",
      "[('gas', 'costs'), ('costs', 'of'), ('of', 'nonfungibletokens'), ('nonfungibletokens', 'nft'), ('nft', 'the'), ('the', 'centralized'), ('centralized', 'system'), ('system', 'based'), ('based', 'on')]\n",
      "\n",
      "aim to the separation of certification this allows high performance\n",
      "[('aim', 'to'), ('to', 'the'), ('the', 'separation'), ('separation', 'of'), ('of', 'certification'), ('certification', 'this'), ('this', 'allows'), ('allows', 'high'), ('high', 'performance')]\n",
      "\n",
      "and then has become one hand blockchain financial services to\n",
      "[('and', 'then'), ('then', 'has'), ('has', 'become'), ('become', 'one'), ('one', 'hand'), ('hand', 'blockchain'), ('blockchain', 'financial'), ('financial', 'services'), ('services', 'to')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate 5 sentences with 10 words with bigram\n",
    "print(\"BIGRAM:\\n\")\n",
    "bigrams = list(nltk.bigrams(words))\n",
    "freq_bigrams = nltk.FreqDist(bigrams)\n",
    "bigrams = []\n",
    "for token_ in freq_bigrams.keys():\n",
    "    bigrams.append(token_)\n",
    "for i in range(num_of_sentences):\n",
    "    sentence = []\n",
    "    tokens_sentence = []\n",
    "    for j in range(num_of_words):\n",
    "        if j == 0:\n",
    "            # Choose the first word randomly\n",
    "            word = random.choice(words)\n",
    "        else:\n",
    "            # Choose the next word based on the previous word\n",
    "            prev_word = sentence[-1]\n",
    "#             choices = [n[1] for n in bigrams if n[0] == prev_word]\n",
    "            choices = []\n",
    "            token_choices = []\n",
    "            for n in bigrams:\n",
    "                if n[0] == prev_word:\n",
    "                    choices.append(n[1])\n",
    "                    token_choices.append(n)\n",
    "            if not choices:\n",
    "                # if there are no choices, then pick a random word\n",
    "                word = random.choice(words)\n",
    "                \n",
    "            else:\n",
    "                 # get a random word from the choices\n",
    "                word = random.choice(choices)\n",
    "                tokens_sentence.append(token_choices[choices.index(word)])\n",
    "        sentence.append(word)\n",
    "    print(\" \".join(sentence))\n",
    "    print(tokens_sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5176ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIGRAM:\n",
      "\n",
      "that direction this paper presents an architecture for a blockchain\n",
      "[('that', 'direction', 'this'), ('direction', 'this', 'paper'), ('this', 'paper', 'presents'), ('paper', 'presents', 'an'), ('presents', 'an', 'architecture'), ('an', 'architecture', 'for'), ('architecture', 'for', 'a'), ('for', 'a', 'blockchain')]\n",
      "\n",
      "by a set of modules is introduced for testing and\n",
      "[('by', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'modules'), ('of', 'modules', 'is'), ('modules', 'is', 'introduced'), ('is', 'introduced', 'for'), ('introduced', 'for', 'testing'), ('for', 'testing', 'and')]\n",
      "\n",
      "metrics and to what extend does the selected blockchain protocol\n",
      "[('metrics', 'and', 'to'), ('and', 'to', 'what'), ('to', 'what', 'extend'), ('what', 'extend', 'does'), ('extend', 'does', 'the'), ('does', 'the', 'selected'), ('the', 'selected', 'blockchain'), ('selected', 'blockchain', 'protocol')]\n",
      "\n",
      "solutions to the blockchain trilemma improving blockchain features and its\n",
      "[('solutions', 'to', 'the'), ('to', 'the', 'blockchain'), ('the', 'blockchain', 'trilemma'), ('blockchain', 'trilemma', 'improving'), ('trilemma', 'improving', 'blockchain'), ('improving', 'blockchain', 'features'), ('blockchain', 'features', 'and'), ('features', 'and', 'its')]\n",
      "\n",
      "aforementioned questions this paper presents an architecture for a blockchain\n",
      "[('aforementioned', 'questions', 'this'), ('questions', 'this', 'paper'), ('this', 'paper', 'presents'), ('paper', 'presents', 'an'), ('presents', 'an', 'architecture'), ('an', 'architecture', 'for'), ('architecture', 'for', 'a'), ('for', 'a', 'blockchain')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate 5 sentences with 10 words with trigram\n",
    "print(\"TRIGRAM:\\n\")\n",
    "trigrams = list(nltk.trigrams(words))\n",
    "trigrams = nltk.FreqDist(trigrams)\n",
    "freq_trigrams = nltk.FreqDist(trigrams)\n",
    "trigrams = []\n",
    "for token_ in freq_trigrams.keys():\n",
    "    trigrams.append(token_)\n",
    "for i in range(num_of_sentences):\n",
    "    sentence = []\n",
    "    tokens_sentence = []\n",
    "    for j in range(num_of_words):\n",
    "        if j == 0:\n",
    "            # Choose the first two words randomly\n",
    "            word = rand.choice(words)\n",
    "            sentence.append(word)\n",
    "        elif j == 1:\n",
    "            prev_words = sentence[-1]\n",
    "#             print(\"Prev word for biugram check\",prev_words)\n",
    "            for n in bigrams:\n",
    "                if n[0] == prev_words:\n",
    "                    sentence.append(n[1])\n",
    "                    break    \n",
    "        else:\n",
    "            # Choose the next word based on the previous two words\n",
    "            prev_words = tuple(sentence[-2:])\n",
    "#             print(\"Prev words\", prev_words)\n",
    "#             choices = [n[2] for n in trigrams if n[:2] == prev_words]\n",
    "            choices = False\n",
    "            for n in trigrams:\n",
    "                if n[:2] == prev_words:\n",
    "                    choices = True\n",
    "                    sentence.append(n[2])\n",
    "                    tokens_sentence.append(n)\n",
    "                    break\n",
    "\n",
    "            if not choices:\n",
    "                # if there are no choices, then pick a random word\n",
    "                word = rand.choice(words)\n",
    "                tokens_sentence.append(word)\n",
    "    print(\" \".join(sentence))\n",
    "    print(tokens_sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "daa3c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-GRAM:\n",
      "\n",
      "innovation the core issue hindering the development of blockchain finance\n",
      "[('innovation', 'the', 'core', 'issue'), ('the', 'core', 'issue', 'hindering'), ('core', 'issue', 'hindering', 'the'), ('issue', 'hindering', 'the', 'development'), ('hindering', 'the', 'development', 'of'), ('the', 'development', 'of', 'blockchain'), ('development', 'of', 'blockchain', 'finance')]\n",
      "\n",
      "authenticate other authentication nodes and contracts will also be required\n",
      "[('authenticate', 'other', 'authentication', 'nodes'), ('other', 'authentication', 'nodes', 'and'), ('authentication', 'nodes', 'and', 'contracts'), ('nodes', 'and', 'contracts', 'will'), ('and', 'contracts', 'will', 'also'), ('contracts', 'will', 'also', 'be'), ('will', 'also', 'be', 'required')]\n",
      "\n",
      "properly attributed we provide the initial prototype application along with\n",
      "[('properly', 'attributed', 'we', 'provide'), ('attributed', 'we', 'provide', 'the'), ('we', 'provide', 'the', 'initial'), ('provide', 'the', 'initial', 'prototype'), ('the', 'initial', 'prototype', 'application'), ('initial', 'prototype', 'application', 'along'), ('prototype', 'application', 'along', 'with')]\n",
      "\n",
      "contracts under the blockchain the relevant laws of internet finance\n",
      "[('contracts', 'under', 'the', 'blockchain'), ('under', 'the', 'blockchain', 'the'), ('the', 'blockchain', 'the', 'relevant'), ('blockchain', 'the', 'relevant', 'laws'), ('the', 'relevant', 'laws', 'of'), ('relevant', 'laws', 'of', 'internet'), ('laws', 'of', 'internet', 'finance')]\n",
      "\n",
      "the performance of blockchains m touloupou k christodoulou a inglezakis\n",
      "[('the', 'performance', 'of', 'blockchains'), ('performance', 'of', 'blockchains', 'm'), ('of', 'blockchains', 'm', 'touloupou'), ('blockchains', 'm', 'touloupou', 'k'), ('m', 'touloupou', 'k', 'christodoulou'), ('touloupou', 'k', 'christodoulou', 'a'), ('k', 'christodoulou', 'a', 'inglezakis')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate 5 sentences with 10 words with N-gram\n",
    "print(\"4-GRAM:\\n\")\n",
    "fourgrams = list(nltk.ngrams(words, 4))\n",
    "fourgrams = nltk.FreqDist(fourgrams)\n",
    "freq_fourgrams = nltk.FreqDist(fourgrams)\n",
    "fourgrams = []\n",
    "for token_ in freq_fourgrams.keys():\n",
    "    fourgrams.append(token_)\n",
    "for i in range(num_of_sentences):\n",
    "    sentence = []\n",
    "    tokens_sentence = []\n",
    "    for j in range(num_of_words):\n",
    "        if j == 0:\n",
    "            # Choose the first two words randomly\n",
    "            word = rand.choice(words)\n",
    "            sentence.append(word)\n",
    "        elif j == 1:\n",
    "            prev_words = sentence[-1]\n",
    "#             print(\"Prev word for biugram check\",prev_words)\n",
    "            for n in bigrams:\n",
    "                if n[0] == prev_words:\n",
    "                    sentence.append(n[1])\n",
    "                    break    \n",
    "        elif j == 2:\n",
    "            prev_words = tuple(sentence[-2:])\n",
    "#             print(\"Prev word for biugram check\",prev_words)\n",
    "            for n in trigrams:\n",
    "                if n[:2] == prev_words:\n",
    "                    sentence.append(n[2])\n",
    "                    break\n",
    "        else:\n",
    "            # Choose the next word based on the previous two words\n",
    "            prev_words = tuple(sentence[-3:])\n",
    "#             print(\"Prev words\", prev_words)\n",
    "#             choices = [n[2] for n in trigrams if n[:2] == prev_words]\n",
    "            choices = False\n",
    "            for n in fourgrams:\n",
    "                if n[:3] == prev_words:\n",
    "                    choices = True\n",
    "                    sentence.append(n[3])\n",
    "                    tokens_sentence.append(n)\n",
    "                    break\n",
    "\n",
    "            if not choices:\n",
    "                # if there are no choices, then pick a random word\n",
    "                word = rand.choice(words)\n",
    "                tokens_sentence.append(word)\n",
    "\n",
    "    print(\" \".join(sentence))\n",
    "    print(tokens_sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abab1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
